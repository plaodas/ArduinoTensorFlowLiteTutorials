{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f92-4Hjy7kA8"
      },
      "source": [
        "<a href=\"https://www.arduino.cc/\"><img src=\"https://raw.githubusercontent.com/sandeepmistry/aimldevfest-workshop-2019/master/images/Arduino_logo_R_highquality.png\" width=200/></a>\n",
        "# Tiny ML on Arduino\n",
        "## Classify objects by color tutorial\n",
        "\n",
        " \n",
        "https://github.com/arduino/ArduinoTensorFlowLiteTutorials/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uvDA8AK7QOq-"
      },
      "source": [
        "## Setup Python Environment \n",
        "\n",
        "The next cell sets up the dependencies in required for the notebook, run it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Y2gs-PL4xDkZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
            "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
            "Requirement already satisfied: pandas in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (2.3.3)\n",
            "Requirement already satisfied: numpy in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (2.1.3)\n",
            "Requirement already satisfied: matplotlib in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (3.10.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from matplotlib) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from matplotlib) (12.0.0)\n",
            "Requirement already satisfied: pyparsing>=3 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: tensorflow in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (2.19.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorflow) (2.3.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorflow) (2.32.5)\n",
            "Requirement already satisfied: setuptools in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorflow) (80.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorflow) (1.14.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorflow) (3.12.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorflow) (2.1.3)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (14.2.0)\n",
            "Requirement already satisfied: namex in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/agake/miniforge/envs/tinyml/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# Setup environment\n",
        "!apt-get -qq install xxd\n",
        "!pip install pandas numpy matplotlib\n",
        "#%tensorflow_version 2.x\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9lwkeshJk7dg"
      },
      "source": [
        "# Upload Data\n",
        "\n",
        "1. Open the panel on the left side of Colab by clicking on the __>__\n",
        "1. Select the Files tab\n",
        "1. Drag `csv` files from your computer to the tab to upload them into colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kSxUeYPNQbOg"
      },
      "source": [
        "# Train Neural Network\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Gxk414PU3oy3"
      },
      "source": [
        "## Parse and prepare the data\n",
        "\n",
        "The next cell parses the csv files and transforms them to a format that will be used to train the full connected neural network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AGChd1FAk5_j"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-05 20:26:57.547639: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-05 20:26:57.560575: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-12-05 20:26:57.654185: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-12-05 20:26:57.730380: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764934017.805307  159316 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764934017.828146  159316 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764934017.988712  159316 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764934017.988758  159316 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764934017.988759  159316 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764934017.988760  159316 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-05 20:26:58.006882: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI AVX_VNNI_INT8 AVX_NE_CONVERT FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version = 2.19.1\n",
            "\n",
            "\u001b[32;4mapple\u001b[0m class will be output \u001b[32m0\u001b[0m of the classifier\n",
            "71 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAAB+CAYAAADskGRTAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAEytJREFUeJzt3XtsFNXbwPFnaWkLWEBA2hKgXCSIVBGpCkgBRUtAiURi0KhggD/qDUolQuFNEBItMfwaJNyCFJBgAn8UCEYMrRFaDBAFihBAJC+1NKRN34K2BaW3nTfn/Ny1pUs5W3Y74/j9JKPMzJnLnmduT2fmjMeyLEsAAAAAwEU62L0CAAAAABBqJDoAAAAAXIdEBwAAAIDrkOgAAAAAcB0SHQAAAACuQ6IDAAAAwHVIdAAAAAC4DokOAAAAANch0QEAAADgOiQ6AAAAAFwn6ESnsLBQpk2bJn369BGPxyP79u276zQFBQUyatQoiYmJkUGDBsmmTZvaur4AAAAAEPpE5+bNmzJixAhZt26dUfni4mKZOnWqpKSkSFFRkSxdulTmz58vubm5wS4aAAAAAIx4LMuy2jyxxyN79+6V6dOn37HM4sWLZf/+/XLhwgX/sLS0NPnpp5/k2LFjbV00AAAAANxRpISZSmZSU1ObDZs8ebLk5ORIfX29dOzYscU0tbW1uvPxer1y/fp16dmzp06uAAAAAPw7WZYlNTU1+lWaDh062JfolJeXS1xcXLNhqr+hoUEqKyslISGhxTRZWVmyYsWKcK8aAAAAgH+o0tJS6du3r32JjnL7XRjf03J3ujuTmZkpGRkZ/v6qqirp37+//jFdu3aVdlP7p0j2/4RwhpbIzRvGReVWrEE5S6Sx0WyekYbh7tTJrJwK3wMmBS2RTrfuXsxriVxvNKuba5GhrRs101iDdbQ8It4edy/n9Yr89lvo6lD95huGcVF/2BhosO2IV0T+z6xYpcesvm9UibHY7iH83abxC2IdTdbPN09vnVnZiOjQ16PRscTwt+h9NYT1E466MZ2fKvunwTahd8J4kxmKdK4yq+8/g9h2qkzq2xLpbvJbRKRzpxDWTRj2A9Nlq2NtfQ/D+f1pto6dO5uVM56nYVzUNlFlePyONtwP6gz3A7V5t/x78j3ExfC3mC43GGrZ9WJ47jfcviMN4xJlVkwaLZH/vWlWPz3UydWgYETzmwWBeUViKw3KRYjcP9Kg3F/zrP7l7sXUtXzv/obzFJG3l4pEx8i9qq6uln79+klsbOvXO2FPdOLj4/VdnaYqKiokMjJSP4oWSHR0tO5up5Kc9k10OorEmG7dhjtfQ5T5Du2NsifRMTnQ+nbUGNOLJ69ZohNj8FvUrKLCkOhEew0TnWizRCcqyqwOow23h7oo80QnxmSmuiLNikUbJjp1LR9FvaPoqBD+btP4BbGOJuvnm6fadk1ERIW+HkN1LPEVjgph/YSjbkznZ7z/q23bdBszqBu1eo1BbDsBHt8OONMow2OZ0ToGcWwM9X5gumx1rPUYbhMNDWbraHJMDmqehnFR1WIUZ8N1VOtn+nq18TnGNC6Gv8V0ucFQyzZ5eyGo6yLT410QiY5R/ahtxzTRMdlu1TWHyXIjRGIMkwyr0ex4ohIdo2uOv6jr+BAkOn8v3mPvd3TGjBkj+fn5zYbl5eVJcnJywPdzAAAAAOBeBZ3o3LhxQ06fPq07X/PR6t9XrlzxP3Y2a9asZi2slZSU6EfRVMtrW7du1Q0RLFq06J5XHgAAAABC8ujaiRMn5JlnnvH3+96lmT17tmzfvl3Kysr8SY8ycOBAOXDggCxcuFDWr1+vW0dYu3atzJgxI9hFAwAAAEB4Ep2JEyf6GxMIRCU7t5swYYKcOnUq2EUBAAAAQJuE/R0dAAAAAGhvJDoAAAAAXIdEBwAAAIDrkOgAAAAAcB0SHQAAAACuQ6IDAAAAwHVIdAAAAAC4DokOAAAAANch0QEAAADgOiQ6AAAAAFyHRAcAAACA65DoAAAAAHAdEh0AAAAArkOiAwAAAMB1SHQAAAAAuA6JDgAAAADXIdEBAAAA4DokOgAAAABch0QHAAAAgOuQ6AAAAABwHRIdAAAAAK5DogMAAADAdUh0AAAAALgOiQ4AAAAA1yHRAQAAAOA6JDoAAAAAXIdEBwAAAIDrkOgAAAAAcJ02JTobNmyQgQMHSkxMjIwaNUqOHDlyx7KHDx8Wj8fTovv555/vZb0BAAAAIHSJzu7duyU9PV2WLVsmRUVFkpKSIlOmTJErV660Ot3FixelrKzM3w0ZMiTYRQMAAABAeBKd7OxsmTt3rsybN0+GDRsma9askX79+snGjRtbna53794SHx/v7yIiIoJdNAAAAACEPtGpq6uTkydPSmpqarPhqv/o0aOtTjty5EhJSEiQSZMmyaFDh1otW1tbK9XV1c06AAAAAAhLolNZWSmNjY0SFxfXbLjqLy8vDziNSm42b94subm5smfPHhk6dKhOdgoLC++4nKysLOnWrZu/U3eMAAAAAMBUpLSBakygKcuyWgzzUYmN6nzGjBkjpaWlsnr1ahk/fnzAaTIzMyUjI8Pfr+7okOwAAAAACMsdnV69eul3a26/e1NRUdHiLk9rRo8eLZcuXbrj+OjoaOnatWuzDgAAAADCkuhERUXp5qTz8/ObDVf9Y8eONZ6Paq1NPdIGAAAAAI54dE09Uvbmm29KcnKyfgxNvX+jmpZOS0vzP3Z29epV2bFjh+5XrbINGDBAhg8frhsz2Llzp35fR3UAAAAA4IhEZ+bMmXLt2jVZuXKl/h5OUlKSHDhwQBITE/V4NazpN3VUcrNo0SKd/HTq1EknPF9//bVMnTo1tL8EAAAAAO6lMYJ33nlHd4Fs3769Wf+HH36oOwAAAABw7AdDAQAAAMDpSHQAAAAAuA6JDgAAAADXIdEBAAAA4DokOgAAAABch0QHAAAAgOuQ6AAAAABwHRIdAAAAAK5DogMAAADAdUh0AAAAALgOiQ4AAAAA1yHRAQAAAOA6JDoAAAAAXIdEBwAAAIDrkOgAAAAAcB0SHQAAAACuQ6IDAAAAwHVIdAAAAAC4DokOAAAAANch0QEAAADgOiQ6AAAAAFyHRAcAAACA65DoAAAAAHAdEh0AAAAArkOiAwAAAMB1SHQAAAAAuA6JDgAAAADXaVOis2HDBhk4cKDExMTIqFGj5MiRI62WLygo0OVU+UGDBsmmTZvaur4AAAAAEPpEZ/fu3ZKeni7Lli2ToqIiSUlJkSlTpsiVK1cCli8uLpapU6fqcqr80qVLZf78+ZKbmxvsogEAAAAgPIlOdna2zJ07V+bNmyfDhg2TNWvWSL9+/WTjxo0By6u7N/3799flVHk13Zw5c2T16tXBLhoAAAAAjERKEOrq6uTkyZOyZMmSZsNTU1Pl6NGjAac5duyYHt/U5MmTJScnR+rr66Vjx44tpqmtrdWdT1VVlf5/dXW1tKvaP0Vu1YVwhpZIreH8LF3hBuUskcZGs3l6vWblIiLMynlE5JZJQUvEY/BbvJbIrUbDuvGGtm5MY2N5RLx/b5ut1rVJ/FQdGszuv785wvzPF7dMZqrq0CQuah3VihrUd129GDOqb9PfbRq/INbReF+1RLyG84zoEPp6DNWxxFc4IoT1E466MZ2fcT2qbdukfiyRyPrQ1rdax3qTdQxim4iMdPZ+YLpsdaytrwthHdoYF7VN1BtebnXoENrfbHyOCfFvMV1uMPSyxfDcb1g/3qAug++u0TA2+rBjck3mEYkw2W7VNYfJb/aK3DK6cPtv2VqT3+IxvOb4i7qWj773a2tfTmCpeLciqAhXVlZKY2OjxMXFNRuu+svLywNOo4YHKt/Q0KDnl5CQ0GKarKwsWbFiRYvh6s4RAAAAgLY4aG+1Lf8spLOrqamRbt263XF8m1JZj8remlDZ1O3D7lY+0HCfzMxMycjI8Pd7vV65fv269OzZs9XltAeVQaqEq7S0VLp27WrruuBvxMWZiIszERfnIjbORFycibj8e+NiWZZOcvr06dNquaASnV69eklERESLuzcVFRUt7tr4xMfHBywfGRmpE5dAoqOjdddU9+7dxUlU4Eh0nIe4OBNxcSbi4lzExpmIizMRl39nXLq1cienTY0RREVF6Wai8/Pzmw1X/WPHjg04zZgxY1qUz8vLk+Tk5IDv5wAAAABAu7e6ph4p27Jli2zdulUuXLggCxcu1E1Lp6Wl+R87mzVrlr+8Gl5SUqKnU+XVdKohgkWLFt3zygMAAABASN7RmTlzply7dk1WrlwpZWVlkpSUJAcOHJDExEQ9Xg1r+k0d9WFRNV4lROvXr9fP0q1du1ZmzJgh/0Tqkbrly5e3eLQO9iIuzkRcnIm4OBexcSbi4kzExZmiHXSt7LHu1i4bAAAAALj90TUAAAAAcDoSHQAAAACuQ6IDAAAAwHVIdAAAAAC4DolOkDZs2KBbkouJidHfFDpy5Eh4IoOACgsLZdq0abr1Po/HI/v27Ws2XrWt8dFHH+nxnTp1kokTJ8q5c+eozTDKysqSJ554QmJjY6V3794yffp0uXjxInFxgI0bN8qjjz7q/2ib+q7ZN9984x/P/uKM/Ucdy9LT0/3DiIs91LlDxaJppz56Tlzsd/XqVXnjjTf0h+Y7d+4sjz32mJw8edI/nn2m/Q0YMKDF/qK6d99911ExIdEJwu7du/XJaNmyZVJUVCQpKSkyZcqUZs1pI7xu3rwpI0aMkHXr1gUc/+mnn0p2drYe/+OPP+qT1PPPPy81NTWEJkwKCgr0ge348eP648ANDQ2SmpqqY0Vc7NW3b19ZtWqVnDhxQnfPPvusvPTSS/6TDfuLvdQxavPmzToZbYq42Gf48OH6Mxm+7uzZs8TFZr/99ps8/fTT+iPz6g8158+fl//85z/SvXt3YmPz8ausyb6izv/KK6+84qzjmGpeGmaefPJJKy0trdmwhx56yFqyZAlVaAO1+e7du9ff7/V6rfj4eGvVqlX+Ybdu3bK6detmbdq0iRi1k4qKCh2bgoIC4uJA999/v7Vlyxb2F5vV1NRYQ4YMsfLz860JEyZYCxYs0MM5jtln+fLl1ogRIwKOIy72Wbx4sTVu3Lg7jic2zrBgwQJr8ODBOh5Oigl3dAzV1dXp26TqL9VNqf6jR4+GIwdFkIqLi6W8vLxZjNTHqiZMmECM2lFVVZX+f48ePYiLgzQ2NsquXbv0nTb1CBv7i73UXdAXXnhBnnvuuWbDiYu9Ll26pB+1UY+ov/rqq3L58mXiYrP9+/dLcnKyvlOgHo8eOXKkfP755/7x7DPOuEbeuXOnzJkzRz++5qSYkOgYqqys1BcKcXFxzYarfhVM2M8XB2JkH3WjLSMjQ8aNGydJSUnExQHUozf33XefPsmkpaXJ3r175eGHH2Z/sZFKOE+dOqXfz7kdxzH7PPXUU7Jjxw45ePCgvpBWsRg7dqxcu3aNuNhIJZvqfcMhQ4bo2Kjj2Pz583WsFPYZ++3bt09+//13eeuttxwXk8h2XZoLqEz19gu724fBXsTIPu+9956cOXNGvv/++xbjiIs9hg4dKqdPn9YnodzcXJk9e7Z+r4q42KO0tFQWLFggeXl5ulGbO2F/aX/qnVufRx55RN/5HDx4sHzxxRcyevRo4mITr9er7+h88sknul/d0VHvGarkZ9asWf5y7DP2ycnJ0fuPuhvalBNiwh0dQ7169ZKIiIgWmWhFRUWLjBX28LWOQ4zs8f777+tHDA4dOqRfgicuzhAVFSUPPvigvlBQdxBUYx6fffYZ+4tN1CPQ6ryhWu2MjIzUnUo8165dq//tO59wHLNfly5ddMKjHmfj/GKfhIQEfRe6qWHDhvkbgiI29iopKZFvv/1W5s2b5x/mpJiQ6ARxsaBOTL5WJXxUv7q1DfupZ6rVztU0Ruq5UXURQYzCR/2FRt3J2bNnj3z33Xc6DsTF2fGqra1lf7HJpEmT9OOE6i6br1NJ6Ouvv67/PWjQII5jDqH2kwsXLugLbc4v9lEtrt3+yYJffvlFEhMT9b+Jjb22bdum351S7xz6OCom7dr0wT/crl27rI4dO1o5OTnW+fPnrfT0dKtLly7Wr7/+aveq/ataKioqKtKd2nyzs7P1v0tKSvR41cKHatVjz5491tmzZ63XXnvNSkhIsKqrq+1eddd6++23dZ0fPnzYKisr83d//PGHvwxxsUdmZqZVWFhoFRcXW2fOnLGWLl1qdejQwcrLyyMuDtK01TWF/cUeH3zwgT6OXb582Tp+/Lj14osvWrGxsf5zPHGxxw8//GBFRkZaH3/8sXXp0iXryy+/tDp37mzt3LnTX4bY2KOxsdHq37+/bhnvdk6JCYlOkNavX28lJiZaUVFR1uOPP+5vQhft49ChQzrBub2bPXu2Hq+aNFRNhKpmDaOjo63x48frHQzhEygeqtu2bZu/DHGxx5w5c/zHqwceeMCaNGmSP8khLs5NdNhf7DFz5kx9Iab+oNmnTx/r5Zdfts6dO0dcHOCrr76ykpKS9HldfdZj8+bNzcazz9jj4MGD+nx/8eLFFuOcEhOP+k/73kMCAAAAgPDiHR0AAAAArkOiAwAAAMB1SHQAAAAAuA6JDgAAAADXIdEBAAAA4DokOgAAAABch0QHAAAAgOuQ6AAAAABwHRIdAAAAAK5DogMAAADAdUh0AAAAALgOiQ4AAAAAcZv/B6ZwE2avG20vAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 1000x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;4mbanana\u001b[0m class will be output \u001b[32m1\u001b[0m of the classifier\n",
            "94 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;4morange\u001b[0m class will be output \u001b[32m2\u001b[0m of the classifier\n",
            "91 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data set parsing and preparation complete.\n",
            "Data set randomization and splitting complete.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import fileinput\n",
        "\n",
        "print(f\"TensorFlow version = {tf.__version__}\\n\")\n",
        "\n",
        "# Set a fixed random seed value, for reproducibility, this will allow us to get\n",
        "# the same random numbers each time the notebook is run\n",
        "SEED = 1337\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "CLASSES = [];\n",
        "\n",
        "for file in os.listdir(\"./SampleData/\"):\n",
        "    if file.endswith(\".csv\"):\n",
        "        CLASSES.append(os.path.splitext(file)[0])\n",
        "\n",
        "CLASSES.sort()\n",
        "\n",
        "SAMPLES_WINDOW_LEN = 1\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "\n",
        "# create a one-hot encoded matrix that is used in the output\n",
        "ONE_HOT_ENCODED_CLASSES = np.eye(NUM_CLASSES)\n",
        "\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "# read each csv file and push an input and output\n",
        "for class_index in range(NUM_CLASSES):\n",
        "  objectClass = CLASSES[class_index]\n",
        "  df = pd.read_csv(\"./SampleData/\" + objectClass + \".csv\")\n",
        "  columns = list(df)\n",
        "  # get rid of pesky empty value lines of csv which cause NaN inputs to TensorFlow\n",
        "  df = df.dropna()\n",
        "  df = df.reset_index(drop=True)\n",
        "   \n",
        "  # calculate the number of objectClass recordings in the file\n",
        "  num_recordings = int(df.shape[0] / SAMPLES_WINDOW_LEN)\n",
        "  print(f\"\\u001b[32;4m{objectClass}\\u001b[0m class will be output \\u001b[32m{class_index}\\u001b[0m of the classifier\")\n",
        "  print(f\"{num_recordings} samples captured for training with inputs {list(df)} \\n\")\n",
        "\n",
        "  # graphing\n",
        "  plt.rcParams[\"figure.figsize\"] = (10,1)\n",
        "  pixels = np.array([df['Red'],df['Green'],df['Blue']],float)\n",
        "  pixels = np.transpose(pixels)\n",
        "  for i in range(num_recordings):\n",
        "    plt.axvline(x=i, linewidth=8, color=tuple(pixels[i]/np.max(pixels[i], axis=0)))\n",
        "  plt.show()\n",
        "  \n",
        "  #tensors\n",
        "  output = ONE_HOT_ENCODED_CLASSES[class_index]\n",
        "  for i in range(num_recordings):\n",
        "    tensor = []\n",
        "    row = []\n",
        "    for c in columns:\n",
        "      row.append(df[c][i])\n",
        "    tensor += row\n",
        "    inputs.append(tensor)\n",
        "    outputs.append(output)\n",
        "\n",
        "# convert the list to numpy array\n",
        "inputs = np.array(inputs)\n",
        "outputs = np.array(outputs)\n",
        "\n",
        "print(\"Data set parsing and preparation complete.\")\n",
        "\n",
        "# Randomize the order of the inputs, so they can be evenly distributed for training, testing, and validation\n",
        "# https://stackoverflow.com/a/37710486/2020087\n",
        "num_inputs = len(inputs)\n",
        "randomize = np.arange(num_inputs)\n",
        "np.random.shuffle(randomize)\n",
        "\n",
        "# Swap the consecutive indexes (0, 1, 2, etc) with the randomized indexes\n",
        "inputs = inputs[randomize]\n",
        "outputs = outputs[randomize]\n",
        "\n",
        "# Split the recordings (group of samples) into three sets: training, testing and validation\n",
        "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
        "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
        "\n",
        "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "print(\"Data set randomization and splitting complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v8qlSAX1b6Yv"
      },
      "source": [
        "## Build & Train the Model\n",
        "\n",
        "Build and train a [TensorFlow](https://www.tensorflow.org) model using the high-level [Keras](https://www.tensorflow.org/guide/keras) API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kGNFa-lX24Qo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-05 20:27:46.237453: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2242 - mae: 0.4460 - val_loss: 0.2216 - val_mae: 0.4437\n",
            "Epoch 2/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2204 - mae: 0.4426 - val_loss: 0.2185 - val_mae: 0.4407\n",
            "Epoch 3/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2183 - mae: 0.4405 - val_loss: 0.2161 - val_mae: 0.4383\n",
            "Epoch 4/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2166 - mae: 0.4387 - val_loss: 0.2140 - val_mae: 0.4361\n",
            "Epoch 5/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2150 - mae: 0.4370 - val_loss: 0.2121 - val_mae: 0.4341\n",
            "Epoch 6/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2134 - mae: 0.4353 - val_loss: 0.2100 - val_mae: 0.4318\n",
            "Epoch 7/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2117 - mae: 0.4334 - val_loss: 0.2078 - val_mae: 0.4295\n",
            "Epoch 8/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2099 - mae: 0.4315 - val_loss: 0.2055 - val_mae: 0.4269\n",
            "Epoch 9/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2080 - mae: 0.4294 - val_loss: 0.2030 - val_mae: 0.4242\n",
            "Epoch 10/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2060 - mae: 0.4272 - val_loss: 0.2004 - val_mae: 0.4213\n",
            "Epoch 11/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2039 - mae: 0.4248 - val_loss: 0.1976 - val_mae: 0.4182\n",
            "Epoch 12/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2017 - mae: 0.4222 - val_loss: 0.1946 - val_mae: 0.4148\n",
            "Epoch 13/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1993 - mae: 0.4194 - val_loss: 0.1916 - val_mae: 0.4113\n",
            "Epoch 14/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1968 - mae: 0.4165 - val_loss: 0.1884 - val_mae: 0.4075\n",
            "Epoch 15/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1942 - mae: 0.4134 - val_loss: 0.1850 - val_mae: 0.4035\n",
            "Epoch 16/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1915 - mae: 0.4100 - val_loss: 0.1815 - val_mae: 0.3992\n",
            "Epoch 17/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1887 - mae: 0.4066 - val_loss: 0.1778 - val_mae: 0.3947\n",
            "Epoch 18/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1857 - mae: 0.4028 - val_loss: 0.1740 - val_mae: 0.3900\n",
            "Epoch 19/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1825 - mae: 0.3987 - val_loss: 0.1699 - val_mae: 0.3848\n",
            "Epoch 20/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1790 - mae: 0.3941 - val_loss: 0.1652 - val_mae: 0.3788\n",
            "Epoch 21/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1749 - mae: 0.3887 - val_loss: 0.1600 - val_mae: 0.3720\n",
            "Epoch 22/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1707 - mae: 0.3829 - val_loss: 0.1549 - val_mae: 0.3650\n",
            "Epoch 23/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1668 - mae: 0.3773 - val_loss: 0.1502 - val_mae: 0.3583\n",
            "Epoch 24/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1631 - mae: 0.3718 - val_loss: 0.1457 - val_mae: 0.3516\n",
            "Epoch 25/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1595 - mae: 0.3662 - val_loss: 0.1412 - val_mae: 0.3450\n",
            "Epoch 26/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1559 - mae: 0.3606 - val_loss: 0.1370 - val_mae: 0.3385\n",
            "Epoch 27/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1525 - mae: 0.3551 - val_loss: 0.1330 - val_mae: 0.3322\n",
            "Epoch 28/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1493 - mae: 0.3497 - val_loss: 0.1293 - val_mae: 0.3260\n",
            "Epoch 29/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1462 - mae: 0.3444 - val_loss: 0.1258 - val_mae: 0.3200\n",
            "Epoch 30/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1432 - mae: 0.3392 - val_loss: 0.1225 - val_mae: 0.3142\n",
            "Epoch 31/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1404 - mae: 0.3341 - val_loss: 0.1194 - val_mae: 0.3086\n",
            "Epoch 32/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1378 - mae: 0.3291 - val_loss: 0.1166 - val_mae: 0.3033\n",
            "Epoch 33/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1353 - mae: 0.3244 - val_loss: 0.1140 - val_mae: 0.2983\n",
            "Epoch 34/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1329 - mae: 0.3199 - val_loss: 0.1117 - val_mae: 0.2936\n",
            "Epoch 35/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1307 - mae: 0.3156 - val_loss: 0.1095 - val_mae: 0.2892\n",
            "Epoch 36/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1286 - mae: 0.3114 - val_loss: 0.1075 - val_mae: 0.2851\n",
            "Epoch 37/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1267 - mae: 0.3075 - val_loss: 0.1058 - val_mae: 0.2813\n",
            "Epoch 38/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1248 - mae: 0.3038 - val_loss: 0.1041 - val_mae: 0.2777\n",
            "Epoch 39/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1230 - mae: 0.3002 - val_loss: 0.1027 - val_mae: 0.2744\n",
            "Epoch 40/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1213 - mae: 0.2968 - val_loss: 0.1013 - val_mae: 0.2713\n",
            "Epoch 41/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1197 - mae: 0.2936 - val_loss: 0.1000 - val_mae: 0.2684\n",
            "Epoch 42/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1181 - mae: 0.2905 - val_loss: 0.0989 - val_mae: 0.2656\n",
            "Epoch 43/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1166 - mae: 0.2875 - val_loss: 0.0977 - val_mae: 0.2630\n",
            "Epoch 44/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1152 - mae: 0.2846 - val_loss: 0.0967 - val_mae: 0.2605\n",
            "Epoch 45/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1138 - mae: 0.2819 - val_loss: 0.0958 - val_mae: 0.2582\n",
            "Epoch 46/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1125 - mae: 0.2793 - val_loss: 0.0949 - val_mae: 0.2560\n",
            "Epoch 47/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1113 - mae: 0.2767 - val_loss: 0.0940 - val_mae: 0.2538\n",
            "Epoch 48/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1101 - mae: 0.2743 - val_loss: 0.0932 - val_mae: 0.2518\n",
            "Epoch 49/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1089 - mae: 0.2720 - val_loss: 0.0924 - val_mae: 0.2499\n",
            "Epoch 50/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1078 - mae: 0.2696 - val_loss: 0.0917 - val_mae: 0.2480\n",
            "Epoch 51/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1067 - mae: 0.2675 - val_loss: 0.0910 - val_mae: 0.2462\n",
            "Epoch 52/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1057 - mae: 0.2653 - val_loss: 0.0903 - val_mae: 0.2444\n",
            "Epoch 53/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1047 - mae: 0.2632 - val_loss: 0.0897 - val_mae: 0.2428\n",
            "Epoch 54/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1037 - mae: 0.2612 - val_loss: 0.0891 - val_mae: 0.2411\n",
            "Epoch 55/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1028 - mae: 0.2592 - val_loss: 0.0885 - val_mae: 0.2396\n",
            "Epoch 56/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1019 - mae: 0.2573 - val_loss: 0.0879 - val_mae: 0.2380\n",
            "Epoch 57/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1010 - mae: 0.2555 - val_loss: 0.0873 - val_mae: 0.2365\n",
            "Epoch 58/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1001 - mae: 0.2537 - val_loss: 0.0868 - val_mae: 0.2351\n",
            "Epoch 59/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0993 - mae: 0.2519 - val_loss: 0.0862 - val_mae: 0.2336\n",
            "Epoch 60/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0985 - mae: 0.2502 - val_loss: 0.0857 - val_mae: 0.2323\n",
            "Epoch 61/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0977 - mae: 0.2485 - val_loss: 0.0852 - val_mae: 0.2309\n",
            "Epoch 62/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0969 - mae: 0.2469 - val_loss: 0.0846 - val_mae: 0.2295\n",
            "Epoch 63/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0962 - mae: 0.2452 - val_loss: 0.0841 - val_mae: 0.2281\n",
            "Epoch 64/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0954 - mae: 0.2436 - val_loss: 0.0836 - val_mae: 0.2268\n",
            "Epoch 65/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0947 - mae: 0.2421 - val_loss: 0.0831 - val_mae: 0.2256\n",
            "Epoch 66/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0940 - mae: 0.2406 - val_loss: 0.0827 - val_mae: 0.2243\n",
            "Epoch 67/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0934 - mae: 0.2391 - val_loss: 0.0822 - val_mae: 0.2231\n",
            "Epoch 68/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0927 - mae: 0.2376 - val_loss: 0.0817 - val_mae: 0.2219\n",
            "Epoch 69/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0920 - mae: 0.2362 - val_loss: 0.0813 - val_mae: 0.2207\n",
            "Epoch 70/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0914 - mae: 0.2348 - val_loss: 0.0809 - val_mae: 0.2195\n",
            "Epoch 71/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0908 - mae: 0.2334 - val_loss: 0.0804 - val_mae: 0.2184\n",
            "Epoch 72/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0902 - mae: 0.2320 - val_loss: 0.0800 - val_mae: 0.2172\n",
            "Epoch 73/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0896 - mae: 0.2307 - val_loss: 0.0796 - val_mae: 0.2162\n",
            "Epoch 74/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0890 - mae: 0.2294 - val_loss: 0.0792 - val_mae: 0.2151\n",
            "Epoch 75/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0884 - mae: 0.2281 - val_loss: 0.0788 - val_mae: 0.2140\n",
            "Epoch 76/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0879 - mae: 0.2269 - val_loss: 0.0784 - val_mae: 0.2129\n",
            "Epoch 77/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0873 - mae: 0.2256 - val_loss: 0.0780 - val_mae: 0.2119\n",
            "Epoch 78/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0868 - mae: 0.2244 - val_loss: 0.0776 - val_mae: 0.2108\n",
            "Epoch 79/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0862 - mae: 0.2232 - val_loss: 0.0772 - val_mae: 0.2098\n",
            "Epoch 80/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0857 - mae: 0.2220 - val_loss: 0.0769 - val_mae: 0.2088\n",
            "Epoch 81/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0852 - mae: 0.2208 - val_loss: 0.0765 - val_mae: 0.2079\n",
            "Epoch 82/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0847 - mae: 0.2197 - val_loss: 0.0762 - val_mae: 0.2069\n",
            "Epoch 83/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0842 - mae: 0.2185 - val_loss: 0.0758 - val_mae: 0.2059\n",
            "Epoch 84/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0837 - mae: 0.2174 - val_loss: 0.0755 - val_mae: 0.2050\n",
            "Epoch 85/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0833 - mae: 0.2163 - val_loss: 0.0752 - val_mae: 0.2041\n",
            "Epoch 86/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0828 - mae: 0.2153 - val_loss: 0.0748 - val_mae: 0.2032\n",
            "Epoch 87/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0824 - mae: 0.2142 - val_loss: 0.0745 - val_mae: 0.2023\n",
            "Epoch 88/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0819 - mae: 0.2132 - val_loss: 0.0742 - val_mae: 0.2014\n",
            "Epoch 89/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0814 - mae: 0.2121 - val_loss: 0.0738 - val_mae: 0.2005\n",
            "Epoch 90/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0810 - mae: 0.2111 - val_loss: 0.0735 - val_mae: 0.1996\n",
            "Epoch 91/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0806 - mae: 0.2101 - val_loss: 0.0732 - val_mae: 0.1987\n",
            "Epoch 92/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0801 - mae: 0.2091 - val_loss: 0.0729 - val_mae: 0.1979\n",
            "Epoch 93/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0797 - mae: 0.2081 - val_loss: 0.0726 - val_mae: 0.1970\n",
            "Epoch 94/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0793 - mae: 0.2071 - val_loss: 0.0723 - val_mae: 0.1962\n",
            "Epoch 95/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0789 - mae: 0.2061 - val_loss: 0.0721 - val_mae: 0.1954\n",
            "Epoch 96/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0785 - mae: 0.2052 - val_loss: 0.0718 - val_mae: 0.1946\n",
            "Epoch 97/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0781 - mae: 0.2042 - val_loss: 0.0715 - val_mae: 0.1938\n",
            "Epoch 98/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0777 - mae: 0.2033 - val_loss: 0.0713 - val_mae: 0.1930\n",
            "Epoch 99/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0773 - mae: 0.2023 - val_loss: 0.0710 - val_mae: 0.1922\n",
            "Epoch 100/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0769 - mae: 0.2014 - val_loss: 0.0707 - val_mae: 0.1914\n",
            "Epoch 101/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0766 - mae: 0.2005 - val_loss: 0.0705 - val_mae: 0.1907\n",
            "Epoch 102/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0762 - mae: 0.1996 - val_loss: 0.0702 - val_mae: 0.1899\n",
            "Epoch 103/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0759 - mae: 0.1988 - val_loss: 0.0700 - val_mae: 0.1892\n",
            "Epoch 104/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0755 - mae: 0.1979 - val_loss: 0.0697 - val_mae: 0.1884\n",
            "Epoch 105/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0752 - mae: 0.1970 - val_loss: 0.0695 - val_mae: 0.1877\n",
            "Epoch 106/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0748 - mae: 0.1962 - val_loss: 0.0693 - val_mae: 0.1870\n",
            "Epoch 107/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0745 - mae: 0.1953 - val_loss: 0.0691 - val_mae: 0.1863\n",
            "Epoch 108/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0742 - mae: 0.1945 - val_loss: 0.0688 - val_mae: 0.1856\n",
            "Epoch 109/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0739 - mae: 0.1937 - val_loss: 0.0686 - val_mae: 0.1849\n",
            "Epoch 110/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0735 - mae: 0.1929 - val_loss: 0.0684 - val_mae: 0.1842\n",
            "Epoch 111/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0732 - mae: 0.1921 - val_loss: 0.0682 - val_mae: 0.1837\n",
            "Epoch 112/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0729 - mae: 0.1914 - val_loss: 0.0680 - val_mae: 0.1830\n",
            "Epoch 113/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0726 - mae: 0.1907 - val_loss: 0.0678 - val_mae: 0.1824\n",
            "Epoch 114/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0721 - mae: 0.1898 - val_loss: 0.0676 - val_mae: 0.1818\n",
            "Epoch 115/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0718 - mae: 0.1890 - val_loss: 0.0673 - val_mae: 0.1811\n",
            "Epoch 116/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0714 - mae: 0.1882 - val_loss: 0.0671 - val_mae: 0.1804\n",
            "Epoch 117/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0711 - mae: 0.1874 - val_loss: 0.0668 - val_mae: 0.1796\n",
            "Epoch 118/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0707 - mae: 0.1866 - val_loss: 0.0665 - val_mae: 0.1789\n",
            "Epoch 119/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0704 - mae: 0.1859 - val_loss: 0.0662 - val_mae: 0.1782\n",
            "Epoch 120/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0701 - mae: 0.1851 - val_loss: 0.0659 - val_mae: 0.1774\n",
            "Epoch 121/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0698 - mae: 0.1845 - val_loss: 0.0655 - val_mae: 0.1766\n",
            "Epoch 122/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0694 - mae: 0.1837 - val_loss: 0.0652 - val_mae: 0.1759\n",
            "Epoch 123/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0691 - mae: 0.1829 - val_loss: 0.0649 - val_mae: 0.1752\n",
            "Epoch 124/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0688 - mae: 0.1822 - val_loss: 0.0646 - val_mae: 0.1745\n",
            "Epoch 125/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0684 - mae: 0.1814 - val_loss: 0.0643 - val_mae: 0.1738\n",
            "Epoch 126/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0681 - mae: 0.1806 - val_loss: 0.0641 - val_mae: 0.1731\n",
            "Epoch 127/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0679 - mae: 0.1798 - val_loss: 0.0638 - val_mae: 0.1724\n",
            "Epoch 128/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0676 - mae: 0.1791 - val_loss: 0.0636 - val_mae: 0.1717\n",
            "Epoch 129/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0673 - mae: 0.1783 - val_loss: 0.0633 - val_mae: 0.1711\n",
            "Epoch 130/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0670 - mae: 0.1776 - val_loss: 0.0631 - val_mae: 0.1704\n",
            "Epoch 131/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0667 - mae: 0.1769 - val_loss: 0.0629 - val_mae: 0.1698\n",
            "Epoch 132/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0664 - mae: 0.1762 - val_loss: 0.0626 - val_mae: 0.1692\n",
            "Epoch 133/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0662 - mae: 0.1755 - val_loss: 0.0624 - val_mae: 0.1687\n",
            "Epoch 134/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0659 - mae: 0.1748 - val_loss: 0.0622 - val_mae: 0.1681\n",
            "Epoch 135/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0656 - mae: 0.1741 - val_loss: 0.0620 - val_mae: 0.1675\n",
            "Epoch 136/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0653 - mae: 0.1734 - val_loss: 0.0618 - val_mae: 0.1669\n",
            "Epoch 137/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0650 - mae: 0.1727 - val_loss: 0.0616 - val_mae: 0.1663\n",
            "Epoch 138/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0648 - mae: 0.1721 - val_loss: 0.0613 - val_mae: 0.1657\n",
            "Epoch 139/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0645 - mae: 0.1714 - val_loss: 0.0611 - val_mae: 0.1651\n",
            "Epoch 140/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0644 - mae: 0.1708 - val_loss: 0.0609 - val_mae: 0.1642\n",
            "Epoch 141/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0641 - mae: 0.1700 - val_loss: 0.0606 - val_mae: 0.1636\n",
            "Epoch 142/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0638 - mae: 0.1694 - val_loss: 0.0605 - val_mae: 0.1630\n",
            "Epoch 143/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0636 - mae: 0.1687 - val_loss: 0.0603 - val_mae: 0.1625\n",
            "Epoch 144/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0634 - mae: 0.1681 - val_loss: 0.0601 - val_mae: 0.1619\n",
            "Epoch 145/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0631 - mae: 0.1674 - val_loss: 0.0599 - val_mae: 0.1614\n",
            "Epoch 146/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0629 - mae: 0.1668 - val_loss: 0.0598 - val_mae: 0.1609\n",
            "Epoch 147/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0627 - mae: 0.1662 - val_loss: 0.0597 - val_mae: 0.1605\n",
            "Epoch 148/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0624 - mae: 0.1656 - val_loss: 0.0596 - val_mae: 0.1600\n",
            "Epoch 149/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0622 - mae: 0.1650 - val_loss: 0.0594 - val_mae: 0.1595\n",
            "Epoch 150/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0620 - mae: 0.1643 - val_loss: 0.0593 - val_mae: 0.1590\n",
            "Epoch 151/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0617 - mae: 0.1637 - val_loss: 0.0592 - val_mae: 0.1587\n",
            "Epoch 152/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0615 - mae: 0.1631 - val_loss: 0.0591 - val_mae: 0.1582\n",
            "Epoch 153/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0612 - mae: 0.1625 - val_loss: 0.0590 - val_mae: 0.1578\n",
            "Epoch 154/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0610 - mae: 0.1619 - val_loss: 0.0589 - val_mae: 0.1573\n",
            "Epoch 155/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0607 - mae: 0.1612 - val_loss: 0.0588 - val_mae: 0.1569\n",
            "Epoch 156/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0605 - mae: 0.1606 - val_loss: 0.0587 - val_mae: 0.1564\n",
            "Epoch 157/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0603 - mae: 0.1600 - val_loss: 0.0586 - val_mae: 0.1560\n",
            "Epoch 158/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0601 - mae: 0.1594 - val_loss: 0.0585 - val_mae: 0.1556\n",
            "Epoch 159/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0598 - mae: 0.1588 - val_loss: 0.0584 - val_mae: 0.1551\n",
            "Epoch 160/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0596 - mae: 0.1582 - val_loss: 0.0583 - val_mae: 0.1547\n",
            "Epoch 161/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0593 - mae: 0.1576 - val_loss: 0.0582 - val_mae: 0.1543\n",
            "Epoch 162/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0591 - mae: 0.1570 - val_loss: 0.0580 - val_mae: 0.1537\n",
            "Epoch 163/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0589 - mae: 0.1563 - val_loss: 0.0579 - val_mae: 0.1532\n",
            "Epoch 164/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0587 - mae: 0.1557 - val_loss: 0.0577 - val_mae: 0.1527\n",
            "Epoch 165/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0585 - mae: 0.1552 - val_loss: 0.0576 - val_mae: 0.1523\n",
            "Epoch 166/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0583 - mae: 0.1546 - val_loss: 0.0575 - val_mae: 0.1518\n",
            "Epoch 167/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0581 - mae: 0.1540 - val_loss: 0.0573 - val_mae: 0.1513\n",
            "Epoch 168/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0579 - mae: 0.1534 - val_loss: 0.0572 - val_mae: 0.1509\n",
            "Epoch 169/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0577 - mae: 0.1528 - val_loss: 0.0571 - val_mae: 0.1504\n",
            "Epoch 170/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0575 - mae: 0.1523 - val_loss: 0.0570 - val_mae: 0.1500\n",
            "Epoch 171/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0573 - mae: 0.1517 - val_loss: 0.0568 - val_mae: 0.1495\n",
            "Epoch 172/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0571 - mae: 0.1512 - val_loss: 0.0567 - val_mae: 0.1491\n",
            "Epoch 173/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0569 - mae: 0.1506 - val_loss: 0.0566 - val_mae: 0.1486\n",
            "Epoch 174/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0567 - mae: 0.1501 - val_loss: 0.0564 - val_mae: 0.1482\n",
            "Epoch 175/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0565 - mae: 0.1495 - val_loss: 0.0563 - val_mae: 0.1478\n",
            "Epoch 176/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0563 - mae: 0.1490 - val_loss: 0.0562 - val_mae: 0.1473\n",
            "Epoch 177/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0561 - mae: 0.1484 - val_loss: 0.0561 - val_mae: 0.1469\n",
            "Epoch 178/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0559 - mae: 0.1479 - val_loss: 0.0559 - val_mae: 0.1464\n",
            "Epoch 179/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0558 - mae: 0.1474 - val_loss: 0.0558 - val_mae: 0.1460\n",
            "Epoch 180/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0556 - mae: 0.1468 - val_loss: 0.0557 - val_mae: 0.1456\n",
            "Epoch 181/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0554 - mae: 0.1463 - val_loss: 0.0555 - val_mae: 0.1452\n",
            "Epoch 182/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0552 - mae: 0.1458 - val_loss: 0.0554 - val_mae: 0.1448\n",
            "Epoch 183/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0550 - mae: 0.1453 - val_loss: 0.0553 - val_mae: 0.1443\n",
            "Epoch 184/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0548 - mae: 0.1448 - val_loss: 0.0551 - val_mae: 0.1439\n",
            "Epoch 185/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0546 - mae: 0.1443 - val_loss: 0.0550 - val_mae: 0.1435\n",
            "Epoch 186/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0545 - mae: 0.1437 - val_loss: 0.0549 - val_mae: 0.1431\n",
            "Epoch 187/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0543 - mae: 0.1432 - val_loss: 0.0547 - val_mae: 0.1427\n",
            "Epoch 188/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0541 - mae: 0.1427 - val_loss: 0.0546 - val_mae: 0.1422\n",
            "Epoch 189/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0539 - mae: 0.1422 - val_loss: 0.0545 - val_mae: 0.1418\n",
            "Epoch 190/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0537 - mae: 0.1416 - val_loss: 0.0543 - val_mae: 0.1413\n",
            "Epoch 191/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0535 - mae: 0.1411 - val_loss: 0.0541 - val_mae: 0.1409\n",
            "Epoch 192/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0534 - mae: 0.1406 - val_loss: 0.0539 - val_mae: 0.1404\n",
            "Epoch 193/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0532 - mae: 0.1401 - val_loss: 0.0538 - val_mae: 0.1400\n",
            "Epoch 194/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0530 - mae: 0.1396 - val_loss: 0.0536 - val_mae: 0.1395\n",
            "Epoch 195/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0529 - mae: 0.1391 - val_loss: 0.0535 - val_mae: 0.1391\n",
            "Epoch 196/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0527 - mae: 0.1387 - val_loss: 0.0533 - val_mae: 0.1387\n",
            "Epoch 197/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0525 - mae: 0.1382 - val_loss: 0.0532 - val_mae: 0.1383\n",
            "Epoch 198/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0524 - mae: 0.1377 - val_loss: 0.0530 - val_mae: 0.1379\n",
            "Epoch 199/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0522 - mae: 0.1372 - val_loss: 0.0528 - val_mae: 0.1375\n",
            "Epoch 200/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0520 - mae: 0.1368 - val_loss: 0.0527 - val_mae: 0.1370\n",
            "Epoch 201/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0519 - mae: 0.1363 - val_loss: 0.0525 - val_mae: 0.1366\n",
            "Epoch 202/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0517 - mae: 0.1359 - val_loss: 0.0524 - val_mae: 0.1362\n",
            "Epoch 203/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0515 - mae: 0.1354 - val_loss: 0.0522 - val_mae: 0.1358\n",
            "Epoch 204/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0514 - mae: 0.1350 - val_loss: 0.0521 - val_mae: 0.1354\n",
            "Epoch 205/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0512 - mae: 0.1345 - val_loss: 0.0519 - val_mae: 0.1350\n",
            "Epoch 206/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0510 - mae: 0.1341 - val_loss: 0.0517 - val_mae: 0.1346\n",
            "Epoch 207/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0509 - mae: 0.1336 - val_loss: 0.0516 - val_mae: 0.1342\n",
            "Epoch 208/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0507 - mae: 0.1332 - val_loss: 0.0514 - val_mae: 0.1338\n",
            "Epoch 209/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0506 - mae: 0.1327 - val_loss: 0.0513 - val_mae: 0.1335\n",
            "Epoch 210/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0504 - mae: 0.1323 - val_loss: 0.0511 - val_mae: 0.1331\n",
            "Epoch 211/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0502 - mae: 0.1318 - val_loss: 0.0509 - val_mae: 0.1327\n",
            "Epoch 212/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0501 - mae: 0.1314 - val_loss: 0.0508 - val_mae: 0.1323\n",
            "Epoch 213/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0499 - mae: 0.1310 - val_loss: 0.0506 - val_mae: 0.1319\n",
            "Epoch 214/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0498 - mae: 0.1305 - val_loss: 0.0504 - val_mae: 0.1315\n",
            "Epoch 215/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0496 - mae: 0.1301 - val_loss: 0.0503 - val_mae: 0.1311\n",
            "Epoch 216/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0494 - mae: 0.1297 - val_loss: 0.0501 - val_mae: 0.1307\n",
            "Epoch 217/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0493 - mae: 0.1293 - val_loss: 0.0499 - val_mae: 0.1304\n",
            "Epoch 218/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0491 - mae: 0.1289 - val_loss: 0.0497 - val_mae: 0.1300\n",
            "Epoch 219/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0490 - mae: 0.1284 - val_loss: 0.0496 - val_mae: 0.1296\n",
            "Epoch 220/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0488 - mae: 0.1280 - val_loss: 0.0494 - val_mae: 0.1292\n",
            "Epoch 221/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0486 - mae: 0.1276 - val_loss: 0.0492 - val_mae: 0.1289\n",
            "Epoch 222/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0485 - mae: 0.1272 - val_loss: 0.0491 - val_mae: 0.1285\n",
            "Epoch 223/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0483 - mae: 0.1268 - val_loss: 0.0489 - val_mae: 0.1281\n",
            "Epoch 224/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0482 - mae: 0.1264 - val_loss: 0.0487 - val_mae: 0.1277\n",
            "Epoch 225/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0480 - mae: 0.1260 - val_loss: 0.0485 - val_mae: 0.1273\n",
            "Epoch 226/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0479 - mae: 0.1256 - val_loss: 0.0483 - val_mae: 0.1269\n",
            "Epoch 227/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0477 - mae: 0.1252 - val_loss: 0.0481 - val_mae: 0.1266\n",
            "Epoch 228/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0475 - mae: 0.1248 - val_loss: 0.0480 - val_mae: 0.1262\n",
            "Epoch 229/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0474 - mae: 0.1244 - val_loss: 0.0478 - val_mae: 0.1258\n",
            "Epoch 230/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0472 - mae: 0.1240 - val_loss: 0.0476 - val_mae: 0.1254\n",
            "Epoch 231/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0471 - mae: 0.1236 - val_loss: 0.0474 - val_mae: 0.1251\n",
            "Epoch 232/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0469 - mae: 0.1232 - val_loss: 0.0472 - val_mae: 0.1247\n",
            "Epoch 233/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0467 - mae: 0.1228 - val_loss: 0.0470 - val_mae: 0.1243\n",
            "Epoch 234/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0466 - mae: 0.1225 - val_loss: 0.0469 - val_mae: 0.1240\n",
            "Epoch 235/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0465 - mae: 0.1221 - val_loss: 0.0467 - val_mae: 0.1236\n",
            "Epoch 236/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0463 - mae: 0.1217 - val_loss: 0.0465 - val_mae: 0.1232\n",
            "Epoch 237/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0461 - mae: 0.1213 - val_loss: 0.0464 - val_mae: 0.1229\n",
            "Epoch 238/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0460 - mae: 0.1210 - val_loss: 0.0462 - val_mae: 0.1225\n",
            "Epoch 239/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0458 - mae: 0.1206 - val_loss: 0.0460 - val_mae: 0.1221\n",
            "Epoch 240/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0457 - mae: 0.1202 - val_loss: 0.0458 - val_mae: 0.1217\n",
            "Epoch 241/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0455 - mae: 0.1198 - val_loss: 0.0456 - val_mae: 0.1214\n",
            "Epoch 242/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0453 - mae: 0.1194 - val_loss: 0.0454 - val_mae: 0.1210\n",
            "Epoch 243/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0452 - mae: 0.1190 - val_loss: 0.0452 - val_mae: 0.1206\n",
            "Epoch 244/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0450 - mae: 0.1186 - val_loss: 0.0450 - val_mae: 0.1202\n",
            "Epoch 245/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0449 - mae: 0.1183 - val_loss: 0.0448 - val_mae: 0.1199\n",
            "Epoch 246/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0447 - mae: 0.1179 - val_loss: 0.0446 - val_mae: 0.1195\n",
            "Epoch 247/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0445 - mae: 0.1175 - val_loss: 0.0444 - val_mae: 0.1191\n",
            "Epoch 248/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0444 - mae: 0.1171 - val_loss: 0.0442 - val_mae: 0.1187\n",
            "Epoch 249/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0442 - mae: 0.1168 - val_loss: 0.0440 - val_mae: 0.1184\n",
            "Epoch 250/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0440 - mae: 0.1164 - val_loss: 0.0438 - val_mae: 0.1180\n",
            "Epoch 251/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0439 - mae: 0.1160 - val_loss: 0.0436 - val_mae: 0.1176\n",
            "Epoch 252/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0437 - mae: 0.1156 - val_loss: 0.0434 - val_mae: 0.1173\n",
            "Epoch 253/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0436 - mae: 0.1152 - val_loss: 0.0432 - val_mae: 0.1169\n",
            "Epoch 254/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0434 - mae: 0.1149 - val_loss: 0.0430 - val_mae: 0.1165\n",
            "Epoch 255/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0432 - mae: 0.1145 - val_loss: 0.0428 - val_mae: 0.1162\n",
            "Epoch 256/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0431 - mae: 0.1141 - val_loss: 0.0426 - val_mae: 0.1158\n",
            "Epoch 257/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0429 - mae: 0.1138 - val_loss: 0.0424 - val_mae: 0.1154\n",
            "Epoch 258/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0427 - mae: 0.1134 - val_loss: 0.0422 - val_mae: 0.1151\n",
            "Epoch 259/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0426 - mae: 0.1130 - val_loss: 0.0420 - val_mae: 0.1147\n",
            "Epoch 260/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0424 - mae: 0.1126 - val_loss: 0.0418 - val_mae: 0.1143\n",
            "Epoch 261/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0422 - mae: 0.1123 - val_loss: 0.0415 - val_mae: 0.1139\n",
            "Epoch 262/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0421 - mae: 0.1119 - val_loss: 0.0413 - val_mae: 0.1136\n",
            "Epoch 263/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0419 - mae: 0.1115 - val_loss: 0.0411 - val_mae: 0.1132\n",
            "Epoch 264/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0417 - mae: 0.1112 - val_loss: 0.0409 - val_mae: 0.1128\n",
            "Epoch 265/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0415 - mae: 0.1108 - val_loss: 0.0407 - val_mae: 0.1124\n",
            "Epoch 266/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0414 - mae: 0.1104 - val_loss: 0.0405 - val_mae: 0.1120\n",
            "Epoch 267/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0412 - mae: 0.1100 - val_loss: 0.0402 - val_mae: 0.1116\n",
            "Epoch 268/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0410 - mae: 0.1097 - val_loss: 0.0400 - val_mae: 0.1112\n",
            "Epoch 269/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0409 - mae: 0.1093 - val_loss: 0.0398 - val_mae: 0.1109\n",
            "Epoch 270/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0407 - mae: 0.1089 - val_loss: 0.0396 - val_mae: 0.1105\n",
            "Epoch 271/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0405 - mae: 0.1086 - val_loss: 0.0394 - val_mae: 0.1101\n",
            "Epoch 272/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0403 - mae: 0.1082 - val_loss: 0.0391 - val_mae: 0.1097\n",
            "Epoch 273/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0402 - mae: 0.1078 - val_loss: 0.0389 - val_mae: 0.1093\n",
            "Epoch 274/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0400 - mae: 0.1075 - val_loss: 0.0387 - val_mae: 0.1089\n",
            "Epoch 275/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0398 - mae: 0.1071 - val_loss: 0.0384 - val_mae: 0.1085\n",
            "Epoch 276/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0396 - mae: 0.1067 - val_loss: 0.0382 - val_mae: 0.1081\n",
            "Epoch 277/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0394 - mae: 0.1064 - val_loss: 0.0380 - val_mae: 0.1077\n",
            "Epoch 278/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0393 - mae: 0.1060 - val_loss: 0.0378 - val_mae: 0.1073\n",
            "Epoch 279/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0391 - mae: 0.1056 - val_loss: 0.0375 - val_mae: 0.1069\n",
            "Epoch 280/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0389 - mae: 0.1053 - val_loss: 0.0373 - val_mae: 0.1065\n",
            "Epoch 281/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0387 - mae: 0.1049 - val_loss: 0.0371 - val_mae: 0.1061\n",
            "Epoch 282/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0385 - mae: 0.1045 - val_loss: 0.0368 - val_mae: 0.1057\n",
            "Epoch 283/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0383 - mae: 0.1042 - val_loss: 0.0366 - val_mae: 0.1053\n",
            "Epoch 284/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0382 - mae: 0.1038 - val_loss: 0.0363 - val_mae: 0.1049\n",
            "Epoch 285/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0380 - mae: 0.1034 - val_loss: 0.0361 - val_mae: 0.1044\n",
            "Epoch 286/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0378 - mae: 0.1031 - val_loss: 0.0359 - val_mae: 0.1040\n",
            "Epoch 287/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0376 - mae: 0.1027 - val_loss: 0.0356 - val_mae: 0.1036\n",
            "Epoch 288/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0374 - mae: 0.1023 - val_loss: 0.0354 - val_mae: 0.1032\n",
            "Epoch 289/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0372 - mae: 0.1020 - val_loss: 0.0351 - val_mae: 0.1028\n",
            "Epoch 290/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0370 - mae: 0.1016 - val_loss: 0.0349 - val_mae: 0.1024\n",
            "Epoch 291/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0368 - mae: 0.1012 - val_loss: 0.0347 - val_mae: 0.1020\n",
            "Epoch 292/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0366 - mae: 0.1008 - val_loss: 0.0344 - val_mae: 0.1016\n",
            "Epoch 293/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0364 - mae: 0.1005 - val_loss: 0.0342 - val_mae: 0.1011\n",
            "Epoch 294/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0362 - mae: 0.1001 - val_loss: 0.0339 - val_mae: 0.1007\n",
            "Epoch 295/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0360 - mae: 0.0997 - val_loss: 0.0337 - val_mae: 0.1003\n",
            "Epoch 296/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0359 - mae: 0.0993 - val_loss: 0.0334 - val_mae: 0.0999\n",
            "Epoch 297/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - mae: 0.0990 - val_loss: 0.0332 - val_mae: 0.0994\n",
            "Epoch 298/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0355 - mae: 0.0986 - val_loss: 0.0330 - val_mae: 0.0990\n",
            "Epoch 299/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0353 - mae: 0.0982 - val_loss: 0.0327 - val_mae: 0.0986\n",
            "Epoch 300/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0351 - mae: 0.0978 - val_loss: 0.0325 - val_mae: 0.0982\n",
            "Epoch 301/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0349 - mae: 0.0974 - val_loss: 0.0322 - val_mae: 0.0977\n",
            "Epoch 302/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mae: 0.0971 - val_loss: 0.0320 - val_mae: 0.0973\n",
            "Epoch 303/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0344 - mae: 0.0967 - val_loss: 0.0317 - val_mae: 0.0969\n",
            "Epoch 304/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0342 - mae: 0.0963 - val_loss: 0.0315 - val_mae: 0.0964\n",
            "Epoch 305/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0340 - mae: 0.0959 - val_loss: 0.0312 - val_mae: 0.0960\n",
            "Epoch 306/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0338 - mae: 0.0955 - val_loss: 0.0310 - val_mae: 0.0955\n",
            "Epoch 307/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0336 - mae: 0.0951 - val_loss: 0.0307 - val_mae: 0.0951\n",
            "Epoch 308/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0334 - mae: 0.0948 - val_loss: 0.0305 - val_mae: 0.0946\n",
            "Epoch 309/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0332 - mae: 0.0944 - val_loss: 0.0303 - val_mae: 0.0942\n",
            "Epoch 310/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0330 - mae: 0.0940 - val_loss: 0.0300 - val_mae: 0.0938\n",
            "Epoch 311/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0328 - mae: 0.0936 - val_loss: 0.0298 - val_mae: 0.0933\n",
            "Epoch 312/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0326 - mae: 0.0932 - val_loss: 0.0295 - val_mae: 0.0929\n",
            "Epoch 313/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0323 - mae: 0.0928 - val_loss: 0.0293 - val_mae: 0.0924\n",
            "Epoch 314/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0321 - mae: 0.0924 - val_loss: 0.0290 - val_mae: 0.0919\n",
            "Epoch 315/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0319 - mae: 0.0920 - val_loss: 0.0288 - val_mae: 0.0915\n",
            "Epoch 316/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0317 - mae: 0.0916 - val_loss: 0.0285 - val_mae: 0.0910\n",
            "Epoch 317/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0315 - mae: 0.0912 - val_loss: 0.0283 - val_mae: 0.0905\n",
            "Epoch 318/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0312 - mae: 0.0908 - val_loss: 0.0280 - val_mae: 0.0901\n",
            "Epoch 319/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0310 - mae: 0.0904 - val_loss: 0.0278 - val_mae: 0.0896\n",
            "Epoch 320/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0308 - mae: 0.0900 - val_loss: 0.0275 - val_mae: 0.0892\n",
            "Epoch 321/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0306 - mae: 0.0896 - val_loss: 0.0273 - val_mae: 0.0887\n",
            "Epoch 322/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0303 - mae: 0.0892 - val_loss: 0.0270 - val_mae: 0.0882\n",
            "Epoch 323/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0301 - mae: 0.0888 - val_loss: 0.0268 - val_mae: 0.0877\n",
            "Epoch 324/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0299 - mae: 0.0884 - val_loss: 0.0265 - val_mae: 0.0873\n",
            "Epoch 325/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0297 - mae: 0.0880 - val_loss: 0.0263 - val_mae: 0.0868\n",
            "Epoch 326/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0294 - mae: 0.0876 - val_loss: 0.0260 - val_mae: 0.0863\n",
            "Epoch 327/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0292 - mae: 0.0872 - val_loss: 0.0258 - val_mae: 0.0858\n",
            "Epoch 328/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0290 - mae: 0.0868 - val_loss: 0.0255 - val_mae: 0.0854\n",
            "Epoch 329/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0287 - mae: 0.0864 - val_loss: 0.0253 - val_mae: 0.0849\n",
            "Epoch 330/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0285 - mae: 0.0859 - val_loss: 0.0250 - val_mae: 0.0844\n",
            "Epoch 331/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0283 - mae: 0.0855 - val_loss: 0.0248 - val_mae: 0.0839\n",
            "Epoch 332/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0280 - mae: 0.0851 - val_loss: 0.0245 - val_mae: 0.0834\n",
            "Epoch 333/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0278 - mae: 0.0847 - val_loss: 0.0243 - val_mae: 0.0830\n",
            "Epoch 334/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0275 - mae: 0.0842 - val_loss: 0.0240 - val_mae: 0.0825\n",
            "Epoch 335/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0273 - mae: 0.0838 - val_loss: 0.0238 - val_mae: 0.0820\n",
            "Epoch 336/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0271 - mae: 0.0834 - val_loss: 0.0235 - val_mae: 0.0815\n",
            "Epoch 337/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0268 - mae: 0.0830 - val_loss: 0.0233 - val_mae: 0.0810\n",
            "Epoch 338/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0266 - mae: 0.0825 - val_loss: 0.0230 - val_mae: 0.0805\n",
            "Epoch 339/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0263 - mae: 0.0821 - val_loss: 0.0228 - val_mae: 0.0800\n",
            "Epoch 340/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0261 - mae: 0.0816 - val_loss: 0.0225 - val_mae: 0.0795\n",
            "Epoch 341/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0258 - mae: 0.0812 - val_loss: 0.0223 - val_mae: 0.0790\n",
            "Epoch 342/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0256 - mae: 0.0807 - val_loss: 0.0220 - val_mae: 0.0785\n",
            "Epoch 343/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0253 - mae: 0.0803 - val_loss: 0.0217 - val_mae: 0.0780\n",
            "Epoch 344/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0251 - mae: 0.0798 - val_loss: 0.0215 - val_mae: 0.0774\n",
            "Epoch 345/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0248 - mae: 0.0794 - val_loss: 0.0212 - val_mae: 0.0769\n",
            "Epoch 346/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0246 - mae: 0.0789 - val_loss: 0.0210 - val_mae: 0.0764\n",
            "Epoch 347/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0244 - mae: 0.0785 - val_loss: 0.0207 - val_mae: 0.0759\n",
            "Epoch 348/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0241 - mae: 0.0780 - val_loss: 0.0205 - val_mae: 0.0754\n",
            "Epoch 349/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0239 - mae: 0.0776 - val_loss: 0.0202 - val_mae: 0.0748\n",
            "Epoch 350/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0236 - mae: 0.0771 - val_loss: 0.0200 - val_mae: 0.0743\n",
            "Epoch 351/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0234 - mae: 0.0766 - val_loss: 0.0197 - val_mae: 0.0738\n",
            "Epoch 352/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0231 - mae: 0.0762 - val_loss: 0.0195 - val_mae: 0.0733\n",
            "Epoch 353/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0229 - mae: 0.0757 - val_loss: 0.0192 - val_mae: 0.0727\n",
            "Epoch 354/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0226 - mae: 0.0752 - val_loss: 0.0190 - val_mae: 0.0722\n",
            "Epoch 355/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0224 - mae: 0.0748 - val_loss: 0.0187 - val_mae: 0.0717\n",
            "Epoch 356/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0221 - mae: 0.0743 - val_loss: 0.0185 - val_mae: 0.0711\n",
            "Epoch 357/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0219 - mae: 0.0738 - val_loss: 0.0182 - val_mae: 0.0706\n",
            "Epoch 358/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0217 - mae: 0.0734 - val_loss: 0.0180 - val_mae: 0.0700\n",
            "Epoch 359/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0214 - mae: 0.0729 - val_loss: 0.0177 - val_mae: 0.0695\n",
            "Epoch 360/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0212 - mae: 0.0724 - val_loss: 0.0175 - val_mae: 0.0690\n",
            "Epoch 361/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0209 - mae: 0.0719 - val_loss: 0.0173 - val_mae: 0.0684\n",
            "Epoch 362/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0207 - mae: 0.0714 - val_loss: 0.0170 - val_mae: 0.0678\n",
            "Epoch 363/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0205 - mae: 0.0710 - val_loss: 0.0168 - val_mae: 0.0673\n",
            "Epoch 364/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0202 - mae: 0.0705 - val_loss: 0.0165 - val_mae: 0.0667\n",
            "Epoch 365/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0200 - mae: 0.0700 - val_loss: 0.0163 - val_mae: 0.0661\n",
            "Epoch 366/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0198 - mae: 0.0695 - val_loss: 0.0160 - val_mae: 0.0656\n",
            "Epoch 367/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0195 - mae: 0.0690 - val_loss: 0.0158 - val_mae: 0.0650\n",
            "Epoch 368/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0193 - mae: 0.0685 - val_loss: 0.0156 - val_mae: 0.0644\n",
            "Epoch 369/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0191 - mae: 0.0680 - val_loss: 0.0153 - val_mae: 0.0639\n",
            "Epoch 370/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0188 - mae: 0.0675 - val_loss: 0.0151 - val_mae: 0.0633\n",
            "Epoch 371/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0186 - mae: 0.0671 - val_loss: 0.0149 - val_mae: 0.0628\n",
            "Epoch 372/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0184 - mae: 0.0666 - val_loss: 0.0147 - val_mae: 0.0622\n",
            "Epoch 373/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0182 - mae: 0.0661 - val_loss: 0.0144 - val_mae: 0.0616\n",
            "Epoch 374/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0180 - mae: 0.0656 - val_loss: 0.0142 - val_mae: 0.0611\n",
            "Epoch 375/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0178 - mae: 0.0651 - val_loss: 0.0140 - val_mae: 0.0605\n",
            "Epoch 376/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0176 - mae: 0.0646 - val_loss: 0.0138 - val_mae: 0.0600\n",
            "Epoch 377/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0173 - mae: 0.0641 - val_loss: 0.0136 - val_mae: 0.0594\n",
            "Epoch 378/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0171 - mae: 0.0636 - val_loss: 0.0134 - val_mae: 0.0588\n",
            "Epoch 379/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0169 - mae: 0.0631 - val_loss: 0.0132 - val_mae: 0.0583\n",
            "Epoch 380/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0167 - mae: 0.0627 - val_loss: 0.0129 - val_mae: 0.0577\n",
            "Epoch 381/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0165 - mae: 0.0622 - val_loss: 0.0127 - val_mae: 0.0572\n",
            "Epoch 382/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0163 - mae: 0.0617 - val_loss: 0.0125 - val_mae: 0.0566\n",
            "Epoch 383/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0162 - mae: 0.0612 - val_loss: 0.0123 - val_mae: 0.0561\n",
            "Epoch 384/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0160 - mae: 0.0607 - val_loss: 0.0121 - val_mae: 0.0556\n",
            "Epoch 385/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0158 - mae: 0.0603 - val_loss: 0.0120 - val_mae: 0.0550\n",
            "Epoch 386/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0156 - mae: 0.0598 - val_loss: 0.0118 - val_mae: 0.0545\n",
            "Epoch 387/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0154 - mae: 0.0593 - val_loss: 0.0116 - val_mae: 0.0540\n",
            "Epoch 388/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0152 - mae: 0.0588 - val_loss: 0.0114 - val_mae: 0.0534\n",
            "Epoch 389/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0151 - mae: 0.0584 - val_loss: 0.0112 - val_mae: 0.0529\n",
            "Epoch 390/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0149 - mae: 0.0579 - val_loss: 0.0110 - val_mae: 0.0524\n",
            "Epoch 391/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0147 - mae: 0.0574 - val_loss: 0.0108 - val_mae: 0.0519\n",
            "Epoch 392/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0146 - mae: 0.0570 - val_loss: 0.0107 - val_mae: 0.0514\n",
            "Epoch 393/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0144 - mae: 0.0565 - val_loss: 0.0105 - val_mae: 0.0508\n",
            "Epoch 394/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0142 - mae: 0.0561 - val_loss: 0.0103 - val_mae: 0.0503\n",
            "Epoch 395/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - mae: 0.0556 - val_loss: 0.0102 - val_mae: 0.0498\n",
            "Epoch 396/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0139 - mae: 0.0552 - val_loss: 0.0100 - val_mae: 0.0493\n",
            "Epoch 397/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0138 - mae: 0.0547 - val_loss: 0.0098 - val_mae: 0.0488\n",
            "Epoch 398/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - mae: 0.0543 - val_loss: 0.0097 - val_mae: 0.0484\n",
            "Epoch 399/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0135 - mae: 0.0539 - val_loss: 0.0095 - val_mae: 0.0479\n",
            "Epoch 400/400\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0133 - mae: 0.0535 - val_loss: 0.0094 - val_mae: 0.0474\n"
          ]
        }
      ],
      "source": [
        "# build the model and train it\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(8, activation='relu')) # relu is used for performance\n",
        "model.add(tf.keras.layers.Dense(5, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')) # softmax is used, because we only expect one class to occur per input\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "history = model.fit(inputs_train, outputs_train, epochs=400, batch_size=4, validation_data=(inputs_validate, outputs_validate))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "guMjtfa42ahM"
      },
      "source": [
        "### Run with Test Data\n",
        "Put our test data into the model and plot the predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "V3Y0CCWJz2EK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "predictions =\n",
            " [[0.033 0.002 0.964]\n",
            " [0.028 0.972 0.   ]\n",
            " [0.125 0.003 0.872]\n",
            " [0.033 0.967 0.   ]\n",
            " [0.033 0.967 0.   ]\n",
            " [0.014 0.    0.986]\n",
            " [0.221 0.77  0.009]\n",
            " [0.024 0.001 0.975]\n",
            " [0.016 0.    0.984]\n",
            " [0.027 0.002 0.971]\n",
            " [0.037 0.963 0.   ]\n",
            " [0.986 0.013 0.001]\n",
            " [0.719 0.    0.281]\n",
            " [0.028 0.972 0.   ]\n",
            " [0.948 0.032 0.021]\n",
            " [0.054 0.946 0.   ]\n",
            " [0.036 0.006 0.959]\n",
            " [0.02  0.001 0.979]\n",
            " [0.038 0.962 0.   ]\n",
            " [0.125 0.003 0.872]\n",
            " [0.417 0.021 0.562]\n",
            " [0.133 0.867 0.   ]\n",
            " [0.992 0.006 0.002]\n",
            " [0.886 0.114 0.001]\n",
            " [0.014 0.    0.986]\n",
            " [0.028 0.972 0.   ]\n",
            " [0.948 0.032 0.021]\n",
            " [0.033 0.002 0.964]\n",
            " [0.02  0.001 0.979]\n",
            " [0.984 0.002 0.014]\n",
            " [0.038 0.962 0.   ]\n",
            " [0.027 0.002 0.971]\n",
            " [0.393 0.059 0.548]\n",
            " [0.024 0.001 0.975]\n",
            " [0.027 0.973 0.   ]\n",
            " [0.126 0.021 0.853]\n",
            " [0.992 0.006 0.002]\n",
            " [0.033 0.967 0.   ]\n",
            " [0.024 0.001 0.975]\n",
            " [0.221 0.77  0.009]\n",
            " [0.029 0.971 0.   ]\n",
            " [0.052 0.948 0.   ]\n",
            " [0.02  0.001 0.979]\n",
            " [0.027 0.002 0.971]\n",
            " [0.017 0.    0.982]\n",
            " [0.026 0.974 0.   ]\n",
            " [0.034 0.005 0.961]\n",
            " [0.017 0.    0.982]\n",
            " [0.948 0.032 0.021]\n",
            " [0.778 0.219 0.004]\n",
            " [0.832 0.01  0.158]]\n",
            "actual =\n",
            " [[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# use the model to predict the test inputs\n",
        "predictions = model.predict(inputs_test)\n",
        "\n",
        "# print the predictions and the expected ouputs\n",
        "print(\"predictions =\\n\", np.round(predictions, decimals=3))\n",
        "print(\"actual =\\n\", outputs_test)\n",
        "\n",
        "# Plot the predictions along with to the test data\n",
        "plt.clf()\n",
        "plt.title('Training data predicted vs actual values')\n",
        "plt.plot(inputs_test, outputs_test, 'b.', label='Actual')\n",
        "plt.plot(inputs_test, predictions, 'r.', label='Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j7DO6xxXVCym"
      },
      "source": [
        "# Convert the Trained Model to Tensor Flow Lite\n",
        "\n",
        "The next cell converts the model to TFlite format. The size in bytes of the model is also printed out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0Xn1-Rn9Cp_8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpk9kc3i72/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpk9kc3i72/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at '/tmp/tmpk9kc3i72'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 3), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  138154213654160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138154213654352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138154213653584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138154176154704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138154176154320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138154176155280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "W0000 00:00:1764934266.283389  159316 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1764934266.283427  159316 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "2025-12-05 20:31:06.283841: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpk9kc3i72\n",
            "2025-12-05 20:31:06.284211: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
            "2025-12-05 20:31:06.284218: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpk9kc3i72\n",
            "I0000 00:00:1764934266.286226  159316 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
            "2025-12-05 20:31:06.286637: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
            "2025-12-05 20:31:06.305485: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpk9kc3i72\n",
            "2025-12-05 20:31:06.309923: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 26011 microseconds.\n",
            "2025-12-05 20:31:06.335403: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model is 2484 bytes\n"
          ]
        }
      ],
      "source": [
        "# Convert the model to the TensorFlow Lite format without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
        "  \n",
        "import os\n",
        "basic_model_size = os.path.getsize(\"gesture_model.tflite\")\n",
        "print(\"Model is %d bytes\" % basic_model_size)\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ykccQn7SXrUX"
      },
      "source": [
        "## Encode the Model in an Arduino Header File \n",
        "\n",
        "The next cell creates a constant byte array that contains the TFlite model. Import it as a tab with the sketch below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9J33uwpNtAku"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Header file, model.h, is 15,352 bytes.\n",
            "\n",
            "Open the side panel (refresh if needed). Double click model.h to download the file.\n"
          ]
        }
      ],
      "source": [
        "!echo \"const unsigned char model[] = {\" > ./content/model.h\n",
        "!cat gesture_model.tflite | xxd -i      >> ./content/model.h\n",
        "!echo \"};\"                              >> ./content/model.h\n",
        "\n",
        "import os\n",
        "model_h_size = os.path.getsize(\"./content/model.h\")\n",
        "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")\n",
        "print(\"\\nOpen the side panel (refresh if needed). Double click model.h to download the file.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1eSkHZaLzMId"
      },
      "source": [
        "# Realtime Classification of Sensor Data on Arduino\n",
        "\n",
        "Now it's time to switch back to the tutorial instructions and run our new model on the [Arduino Nano 33 BLE Sense](https://www.arduino.cc/en/Guide/NANO33BLE)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "FruitToEmoji-GIT.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "tinyml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
